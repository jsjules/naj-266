{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNAyGJDO6POHKGClUn5+BBz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dF4BWLoEWgd_","executionInfo":{"status":"ok","timestamp":1753325746711,"user_tz":240,"elapsed":78241,"user":{"displayName":"Arun Agarwal","userId":"13941284362159407149"}},"outputId":"5aee3ce4-f9d4-4e28-9ff3-fc52738ad41b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Mount Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# Imports\n","import os\n","import re\n","import math\n","import string\n","import operator\n","import pandas as pd\n","from collections import Counter, defaultdict\n","import numpy as np"],"metadata":{"id":"P0Yx8lyHWogf","executionInfo":{"status":"ok","timestamp":1753325748641,"user_tz":240,"elapsed":1091,"user":{"displayName":"Arun Agarwal","userId":"13941284362159407149"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# File paths\n","DATA_DIR = \"/content/drive/MyDrive/266_final_project/data/full_dataset\"\n","EMOTION_FILE = \"/content/drive/MyDrive/266_final_project/data/emotions.txt\"\n","OUTPUT_CSV = \"/content/drive/MyDrive/266_final_project/emotion_words.csv\""],"metadata":{"id":"lZKBsL-8W7we","executionInfo":{"status":"ok","timestamp":1753325800932,"user_tz":240,"elapsed":4,"user":{"displayName":"Arun Agarwal","userId":"13941284362159407149"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Text preprocessing\n","punct_chars = list((set(string.punctuation) | {\n","    \"’\", \"‘\", \"–\", \"—\", \"~\", \"|\", \"“\", \"”\", \"…\", \"'\", \"`\", \"_\", \"“\"\n","}) - set([\"#\"]))\n","punct_chars.sort()\n","punctuation = \"\".join(punct_chars)\n","replace = re.compile(\"[%s]\" % re.escape(punctuation))\n","\n","def CleanText(text):\n","    if isinstance(text, float):\n","        return []\n","    text = text.lower()\n","    text = re.sub(r\"http\\S*|\\S*\\.com\\S*|\\S*www\\S*\", \" \", text)\n","    text = re.sub(r\"\\s@\\S+\", \" \", text)\n","    text = replace.sub(\" \", text)\n","    text = re.sub(r\"\\s+\", \" \", text).strip()\n","    return [w for w in text.split() if len(w) > 2]"],"metadata":{"id":"MwMNhZJuXE-9","executionInfo":{"status":"ok","timestamp":1753325805053,"user_tz":240,"elapsed":12,"user":{"displayName":"Arun Agarwal","userId":"13941284362159407149"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Agreement and word count helpers\n","def CheckAgreement(ex, min_agreement, all_emotions, max_agreement=100):\n","    sum_ratings = ex[all_emotions].sum(axis=0)\n","    agreement = (sum_ratings >= min_agreement) & (sum_ratings <= max_agreement)\n","    return \",\".join(sum_ratings.index[agreement].tolist())\n","\n","def GetCounts(df):\n","    words = []\n","    for t in df[\"text\"]:\n","        words.extend(t)\n","    return Counter(words)\n","\n","def LogOdds(counts1, counts2, prior, zscore=True):\n","    sigmasquared = defaultdict(float)\n","    sigma = defaultdict(float)\n","    delta = defaultdict(float)\n","    n1, n2 = sum(counts1.values()), sum(counts2.values())\n","    nprior = sum(prior.values())\n","\n","    for word in prior:\n","        if prior[word] == 0:\n","            delta[word] = 0\n","            continue\n","        l1 = (counts1[word] + prior[word]) / ((n1 + nprior) - (counts1[word] + prior[word]))\n","        l2 = (counts2[word] + prior[word]) / ((n2 + nprior) - (counts2[word] + prior[word]))\n","        sigmasquared[word] = 1 / (counts1[word] + prior[word]) + 1 / (counts2[word] + prior[word])\n","        sigma[word] = math.sqrt(sigmasquared[word])\n","        delta[word] = math.log(l1) - math.log(l2)\n","        if zscore:\n","            delta[word] /= sigma[word]\n","    return delta"],"metadata":{"id":"az5x1CHjXJ2C","executionInfo":{"status":"ok","timestamp":1753325861099,"user_tz":240,"elapsed":15,"user":{"displayName":"Arun Agarwal","userId":"13941284362159407149"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Load dataset\n","print(\"Loading data...\")\n","dfs = [pd.read_csv(os.path.join(DATA_DIR, f)) for f in os.listdir(DATA_DIR) if f.endswith(\".csv\")]\n","data = pd.concat(dfs)\n","print(f\"{len(set(data['id']))} unique examples, {len(data)} annotations\")\n","\n","# Load emotions\n","with open(EMOTION_FILE, \"r\") as f:\n","    all_emotions = f.read().splitlines()\n","print(f\"{len(all_emotions)} emotion categories\")\n","\n","# Clean text\n","print(\"Processing text...\")\n","data[\"text\"] = data[\"text\"].apply(CleanText)\n","\n","# Compute agreement labels\n","agree_dict = data.groupby(\"id\").apply(CheckAgreement, 2, all_emotions).to_dict()\n","data[\"agreement\"] = data[\"id\"].map(agree_dict)\n","data = data[~data[\"agreement\"].isnull()]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ys5CM60rXXhr","executionInfo":{"status":"ok","timestamp":1753326086138,"user_tz":240,"elapsed":73455,"user":{"displayName":"Arun Agarwal","userId":"13941284362159407149"}},"outputId":"d4430b60-8cee-4ee7-c6df-dd8c261e090a"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading data...\n","58011 unique examples, 211225 annotations\n","28 emotion categories\n","Processing text...\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-7-1235929822.py:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  agree_dict = data.groupby(\"id\").apply(CheckAgreement, 2, all_emotions).to_dict()\n"]}]},{"cell_type":"code","source":["# Extract top words per emotion\n","dicts = []\n","\n","for e in all_emotions:\n","    print(f\"Processing emotion: {e}\")\n","    contains = data[\"agreement\"].str.contains(e)\n","    emotion_words = GetCounts(data[contains])\n","    other_words = GetCounts(data[~contains])\n","    prior = Counter(emotion_words) + Counter(other_words)\n","    emotion_words_total = sum(emotion_words.values())\n","\n","    delta = LogOdds(emotion_words, other_words, prior, zscore=True)\n","\n","    c = 0\n","    for k, v in sorted(delta.items(), key=operator.itemgetter(1), reverse=True):\n","        if v < 3:\n","            continue\n","        dicts.append({\n","            \"emotion\": e,\n","            \"word\": k,\n","            \"odds\": \"%.2f\" % v,\n","            \"freq\": \"%.3f\" % (emotion_words[k] / emotion_words_total)\n","        })\n","        c += 1\n","        if c < 11:\n","            print(f\"{k} ({v:.2f})\")\n","    print(\"--------\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2ZD5kE2sX8io","executionInfo":{"status":"ok","timestamp":1753326128547,"user_tz":240,"elapsed":22175,"user":{"displayName":"Arun Agarwal","userId":"13941284362159407149"}},"outputId":"95743caa-3186-454b-9328-9af06c905e3e"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing emotion: admiration\n","great (41.80)\n","awesome (31.18)\n","amazing (29.65)\n","good (26.87)\n","beautiful (22.87)\n","nice (20.57)\n","appreciate (17.56)\n","cute (17.55)\n","best (17.26)\n","pretty (13.86)\n","--------\n","Processing emotion: amusement\n","lol (65.47)\n","haha (32.19)\n","funny (26.68)\n","lmao (20.18)\n","hilarious (18.42)\n","fun (16.92)\n","hahaha (15.62)\n","laugh (14.26)\n","laughed (12.98)\n","joke (12.25)\n","--------\n","Processing emotion: anger\n","fuck (23.22)\n","hate (17.37)\n","fucking (16.97)\n","angry (10.82)\n","dare (10.25)\n","shut (7.60)\n","stupid (7.21)\n","hell (6.67)\n","idiot (6.37)\n","asshole (6.14)\n","--------\n","Processing emotion: annoyance\n","annoying (14.32)\n","stupid (12.72)\n","fucking (11.77)\n","shit (9.11)\n","dumb (8.69)\n","frustrating (8.06)\n","idiot (7.88)\n","annoyed (7.66)\n","fuck (7.54)\n","damn (7.38)\n","--------\n","Processing emotion: approval\n","agree (24.39)\n","not (12.37)\n","don (11.42)\n","agreed (11.37)\n","true (11.16)\n","yes (11.12)\n","yeah (8.46)\n","disagree (8.35)\n","right (7.73)\n","doesn (7.13)\n","--------\n","Processing emotion: caring\n","you (11.26)\n","worry (10.87)\n","careful (8.91)\n","stay (8.48)\n","your (7.99)\n","bless (7.97)\n","yourself (7.60)\n","help (7.14)\n","luck (7.08)\n","safe (7.03)\n","--------\n","Processing emotion: confusion\n","confused (18.48)\n","why (10.55)\n","sure (9.73)\n","what (9.30)\n","confusing (7.54)\n","understand (7.31)\n","idk (6.71)\n","don (6.48)\n","know (6.15)\n","confusion (5.74)\n","--------\n","Processing emotion: curiosity\n","curious (22.34)\n","what (17.84)\n","why (12.80)\n","how (10.71)\n","did (10.15)\n","curiosity (9.38)\n","does (8.81)\n","you (8.03)\n","where (6.55)\n","interesting (6.06)\n","--------\n","Processing emotion: desire\n","wish (29.04)\n","want (7.91)\n","wanted (5.34)\n","could (5.28)\n","ambitious (4.31)\n","hope (3.92)\n","dream (3.75)\n","need (3.29)\n","wanna (3.16)\n","bdsm (3.15)\n","--------\n","Processing emotion: disappointment\n","disappointing (10.57)\n","disappointed (9.71)\n","bad (8.16)\n","disappointment (7.46)\n","unfortunately (6.59)\n","upset (6.11)\n","depressing (6.06)\n","miss (5.49)\n","upsetting (5.20)\n","lost (5.01)\n","--------\n","Processing emotion: disapproval\n","not (14.93)\n","don (12.73)\n","disagree (8.32)\n","nope (7.74)\n","doesn (6.74)\n","wrong (6.33)\n","nah (5.88)\n","unpopular (5.58)\n","isn (4.67)\n","refuse (4.38)\n","--------\n","Processing emotion: disgust\n","disgusting (22.53)\n","awful (13.25)\n","worst (12.03)\n","worse (11.59)\n","weird (7.92)\n","nasty (7.32)\n","disgusted (5.46)\n","ugly (5.23)\n","creepy (4.97)\n","gross (4.71)\n","--------\n","Processing emotion: embarrassment\n","embarrassing (12.04)\n","shame (10.31)\n","awkward (10.29)\n","embarrassment (8.15)\n","embarrassed (7.26)\n","ashamed (7.16)\n","shameful (3.83)\n","embarassed (3.72)\n","embarassing (3.72)\n","oops (3.60)\n","--------\n","Processing emotion: excitement\n","excited (20.64)\n","happy (7.93)\n","cake (7.78)\n","wow (7.53)\n","exciting (6.64)\n","interesting (6.61)\n","wait (6.17)\n","birthday (5.34)\n","merrily (4.98)\n","yay (4.38)\n","--------\n","Processing emotion: fear\n","scared (15.76)\n","afraid (15.25)\n","scary (14.79)\n","terrible (11.08)\n","terrifying (10.91)\n","fear (9.79)\n","horrible (8.29)\n","terrified (6.91)\n","scares (6.65)\n","dangerous (6.56)\n","--------\n","Processing emotion: gratitude\n","thanks (74.75)\n","thank (68.29)\n","for (23.36)\n","you (17.36)\n","sharing (16.98)\n","appreciate (15.25)\n","welcome (11.95)\n","congrats (10.95)\n","advice (10.82)\n","info (9.85)\n","--------\n","Processing emotion: grief\n","died (5.85)\n","rip (4.33)\n","--------\n","Processing emotion: joy\n","happy (30.85)\n","glad (26.28)\n","enjoy (19.10)\n","enjoyed (11.45)\n","fun (11.36)\n","cheers (9.09)\n","cake (8.64)\n","joy (7.47)\n","enjoying (7.46)\n","day (6.48)\n","--------\n","Processing emotion: love\n","love (75.16)\n","loved (20.99)\n","favorite (12.17)\n","loves (11.72)\n","loving (8.78)\n","like (8.63)\n","lovely (5.61)\n","cute (4.92)\n","name (4.79)\n","favourite (4.67)\n","--------\n","Processing emotion: nervousness\n","nervous (8.13)\n","worried (7.28)\n","anxiety (5.93)\n","anxious (3.91)\n","worrying (3.53)\n","demonize (3.31)\n","--------\n","Processing emotion: optimism\n","hope (44.71)\n","hopefully (18.45)\n","luck (17.98)\n","hoping (15.52)\n","will (7.70)\n","good (7.61)\n","soon (7.50)\n","better (6.00)\n","wish (5.09)\n","hopeful (4.67)\n","--------\n","Processing emotion: pride\n","proud (13.59)\n","pride (3.91)\n","accomplishment (3.58)\n","--------\n","Processing emotion: realization\n","realize (13.87)\n","realized (12.12)\n","realised (7.16)\n","realization (6.01)\n","thought (5.37)\n","forgot (4.99)\n","was (4.93)\n","didn (4.92)\n","realizing (4.91)\n","reminds (4.79)\n","--------\n","Processing emotion: relief\n","glad (4.45)\n","relieving (4.07)\n","relieved (3.95)\n","relief (3.92)\n","--------\n","Processing emotion: remorse\n","sorry (37.65)\n","regret (8.80)\n","apologies (6.71)\n","apologize (5.81)\n","guilt (4.45)\n","guilty (3.92)\n","loss (3.73)\n","regretting (3.19)\n","remorse (3.16)\n","--------\n","Processing emotion: sadness\n","sad (30.33)\n","sadly (15.25)\n","sorry (15.10)\n","painful (9.70)\n","hurts (9.21)\n","crying (8.93)\n","miss (8.24)\n","heartbreaking (6.92)\n","cry (6.77)\n","loss (6.65)\n","--------\n","Processing emotion: surprise\n","wow (21.40)\n","surprised (21.16)\n","wonder (14.38)\n","shocked (12.20)\n","omg (10.45)\n","wondering (8.84)\n","surprise (8.43)\n","surprising (6.24)\n","believe (5.99)\n","wondered (5.99)\n","--------\n","Processing emotion: neutral\n","name (19.15)\n","they (16.21)\n","the (9.39)\n","remindme (7.52)\n","his (7.42)\n","she (7.11)\n","only (6.25)\n","from (5.87)\n","there (5.84)\n","wall (5.31)\n","--------\n"]}]},{"cell_type":"code","source":["# Save to CSV\n","emotion_words_df = pd.DataFrame(dicts)\n","emotion_words_df.to_csv(OUTPUT_CSV, index=False, encoding=\"utf-8\")\n","print(f\"\\nSaved top emotion words to {OUTPUT_CSV}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S5FmiG09YNWn","executionInfo":{"status":"ok","timestamp":1753326187256,"user_tz":240,"elapsed":29,"user":{"displayName":"Arun Agarwal","userId":"13941284362159407149"}},"outputId":"ff2727ee-70df-4799-bd0e-99894cb17a04"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Saved top emotion words to /content/drive/MyDrive/266_final_project/emotion_words.csv\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"VtyKWOEoYnIr"},"execution_count":null,"outputs":[]}]}